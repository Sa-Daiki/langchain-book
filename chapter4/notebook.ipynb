{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUj2y-stek1W"
      },
      "source": [
        "# 4. LangChain解説"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4oSu5DqWgpG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3cSlNQV9ZBB"
      },
      "source": [
        "## 4-1 LangChainの概要"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqgjYwQUemjV"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.0.292 openai==0.28.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMModXMNetUP"
      },
      "source": [
        "## 4-2 Language models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3elDRjh9jVa"
      },
      "source": [
        "### LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY3sdyngepk-"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
        "\n",
        "result = llm(\"自己紹介してください。\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvqkiiI-9mI9"
      },
      "source": [
        "### Chat models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLI_K6YIewJn"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"こんにちは！私はジョンと言います！\"),\n",
        "    AIMessage(content=\"こんにちは、ジョンさん！どのようにお手伝いできますか？\"),\n",
        "    HumanMessage(content= \"私の名前が分かりますか？\")\n",
        "]\n",
        "\n",
        "result = chat(messages)\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLRYe3Ec9qAO"
      },
      "source": [
        "### Callbackを使ったストリーミング"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLxGXw7zgXlR"
      },
      "outputs": [],
      "source": [
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    streaming=True,\n",
        "    callbacks=[StreamingStdOutCallbackHandler()],\n",
        ")\n",
        "\n",
        "messages = [HumanMessage(content=\"自己紹介してください\")]\n",
        "result = chat(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRH_6qBQnEjZ"
      },
      "source": [
        "## 4-3 Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJvnkWfA9tIT"
      },
      "source": [
        "### Prompt templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLfdULPOjUDY"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "以下の料理のレシピを考えてください。\n",
        "\n",
        "料理名: {dish}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "   input_variables=[\"dish\"],\n",
        "   template=template,\n",
        ")\n",
        "\n",
        "result = prompt.format(dish=\"カレー\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIYyxXfj9viN"
      },
      "source": [
        "### ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUvu-76mnWBK"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessagePromptTemplate.from_template(\"あなたは{country}料理のプロフェッショナルです。\"),\n",
        "    HumanMessagePromptTemplate.from_template(\"以下の料理のレシピを考えてください。\\n\\n料理名: {dish}\")\n",
        "])\n",
        "\n",
        "messages = chat_prompt.format_prompt(country=\"イギリス\", dish=\"肉じゃが\").to_messages()\n",
        "\n",
        "print(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-WsdEpEsNta"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "result = chat(messages)\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9SAbwnNwFQq"
      },
      "source": [
        "## 4-4 Output Parsers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gUPEasNNBlP"
      },
      "source": [
        "### PydanticOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEkmkZixwEdi"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "   ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
        "   steps: list[str] = Field(description=\"steps to make the dish\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aosaD-s-wExZ"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Recipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blhjs33M-AHZ"
      },
      "outputs": [],
      "source": [
        "format_instructions = parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21EfCn8b-AFY"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"料理のレシピを考えてください。\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "料理名: {dish}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "   template=template,\n",
        "   input_variables=[\"dish\"],\n",
        "   partial_variables={\"format_instructions\": format_instructions}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5Y0KvYk-ADU"
      },
      "outputs": [],
      "source": [
        "formatted_prompt = prompt.format(dish=\"カレー\")\n",
        "\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gQjKsGy9__B"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "messages = [HumanMessage(content=formatted_prompt)]\n",
        "output = chat(messages)\n",
        "\n",
        "print(output.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY4cBqNZ9_1x"
      },
      "outputs": [],
      "source": [
        "recipe = parser.parse(output.content)\n",
        "print(recipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUVnoApz-v9O"
      },
      "source": [
        "## 4-5 Chains"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU0czqQn-xgL"
      },
      "source": [
        "### LLMChain―PromptTemplate・Language model・OutputParserをつなぐ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpPIlgjpyroZ"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "   ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
        "   steps: list[str] = Field(description=\"steps to make the dish\")\n",
        "\n",
        "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
        "\n",
        "template = \"\"\"料理のレシピを考えてください。\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "料理名: {dish}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "   template=template,\n",
        "   input_variables=[\"dish\"],\n",
        "   partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jys6cH41C4NW"
      },
      "outputs": [],
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "chain = LLMChain(prompt=prompt, llm=chat, output_parser=output_parser)\n",
        "\n",
        "recipe = chain.run(dish=\"カレー\")\n",
        "\n",
        "print(type(recipe))\n",
        "print(recipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCt-YzvX-z4k"
      },
      "source": [
        "### SimpleSequentialChain―ChainとChainをつなぐ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcL-GWtO-0v4"
      },
      "outputs": [],
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "cot_template = \"\"\"以下の質問に回答してください。\n",
        "\n",
        "質問: {question}\n",
        "\n",
        "ステップバイステップで考えましょう。\n",
        "\"\"\"\n",
        "\n",
        "cot_prompt = PromptTemplate(\n",
        "   input_variables=[\"question\"],\n",
        "   template=cot_template,\n",
        ")\n",
        "\n",
        "cot_chain = LLMChain(llm=chat, prompt=cot_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGTWjr3rKBCX"
      },
      "outputs": [],
      "source": [
        "summarize_template = \"\"\"以下の文章を結論だけ一言に要約してください。\n",
        "\n",
        "{input}\n",
        "\"\"\"\n",
        "summarize_prompt = PromptTemplate(\n",
        "   input_variables=[\"input\"],\n",
        "   template=summarize_template,\n",
        ")\n",
        "\n",
        "summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYGaG5tuKEVX"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "cot_summarize_chain = SimpleSequentialChain(chains=[cot_chain, summarize_chain])\n",
        "\n",
        "result = cot_summarize_chain(\n",
        "   \"私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\"\n",
        ")\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "上記の入力は [Chain-of-Thoughtプロンプティング | Prompt Engineering Guide](https://www.promptingguide.ai/jp/techniques/cot) から引用しました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jpeYc6ARqBz"
      },
      "source": [
        "## 4-6 Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yOh1zrMRrbn"
      },
      "source": [
        "### ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WugAW9-LKGJ0"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
        "conversation = ConversationChain(\n",
        "    llm=chat,\n",
        "    memory=ConversationBufferMemory()\n",
        ")\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"You: \")\n",
        "    ai_message = conversation.run(input=user_message)\n",
        "    print(f\"AI: {ai_message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### （コラム）Chat modelsでMemoryを使う場合の注意"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoEzLBS7KLmH"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"こんにちは！私はジョンと言います！\"),\n",
        "    AIMessage(content=\"こんにちは、ジョンさん！どのようにお手伝いできますか？\"),\n",
        "    HumanMessage(content= \"私の名前が分かりますか？\")\n",
        "]\n",
        "\n",
        "result = chat(messages)\n",
        "print(result.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
